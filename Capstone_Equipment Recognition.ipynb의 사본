{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SJL329CNchUtNxl62B-K6t8ZP1EXfMnu","timestamp":1716953410776}],"authorship_tag":"ABX9TyNmpghK88BNj54y9qrM1Y3j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KCu7YVcnRpQC"},"outputs":[],"source":["import os\n","import requests\n","from google.colab import drive\n","\n","# Google Drive 경로 설정\n","drive_folder_path = '/content/drive/My Drive/캡스톤/naver_valid_1'\n","\n","# 폴더가 없는 경우 생성\n","if not os.path.exists(drive_folder_path):\n","    os.makedirs(drive_folder_path)\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 네이버 이미지 검색 함수\n","def naver_image_search(query, client_id, client_secret, display=100, start=1):\n","    url = 'https://openapi.naver.com/v1/search/image'\n","    headers = {\n","        'X-Naver-Client-Id': client_id,\n","        'X-Naver-Client-Secret': client_secret\n","    }\n","    params = {\n","        'query': query,\n","        'display': display,\n","        'start': start\n","    }\n","    response = requests.get(url, headers=headers, params=params)\n","    data = response.json()\n","    if 'items' in data:\n","        return [item['link'] for item in data['items']]\n","    else:\n","        return []\n","\n","# 네이버 검색 API 인증 정보\n","client_id = 'ZEWIgDTJQdIqT4US28qZ'\n","client_secret = '91jLpWvoN9'\n","\n","# 검색어 설정\n","query = 'lat pull down'\n","\n","# 이미지 검색 및 다운로드 후 Google Drive에 저장\n","image_urls = []\n","for start in range(1, 11):  # 각 요청 당 최대 100개, 10번 반복하여 최대 1000개\n","    image_urls.extend(naver_image_search(query, client_id, client_secret, display=100, start=start))\n","\n","# 이미지 다운로드 및 Google Drive 저장\n","saved_count = 0\n","for idx, url in enumerate(image_urls):\n","    try:\n","        response = requests.get(url, timeout=10)\n","        if response.status_code == 200:\n","            file_name = f'lat_pull_down_{idx + 1}.jpg'\n","            file_path = os.path.join(drive_folder_path, file_name)\n","            with open(file_path, 'wb') as file:\n","                file.write(response.content)\n","            saved_count += 1\n","            print(f'Successfully saved {file_name}')\n","        else:\n","            print(f\"Failed to download image {url}: Status code {response.status_code}\")\n","    except requests.RequestException as e:\n","        print(f\"Failed to download image {url}: {e}\")\n","    except Exception as e:\n","        print(f\"Failed to save image {url}: {e}\")\n","\n","print(f\"Total images saved: {saved_count}\")\n"]},{"cell_type":"markdown","source":["네이버 api를 통해 검색한 이미지url을 이미지로 변환하여 구글 드라이브에 저장"],"metadata":{"id":"63RO0VE3SmvK"}},{"cell_type":"code","source":["from PIL import Image\n","\n","# 이미지 파일 유효성 검사 함수\n","def is_image_file(file_path):\n","    try:\n","        with Image.open(file_path) as img:\n","            img.verify()\n","        return True\n","    except (IOError, SyntaxError) as e:\n","        print(f\"Bad file: {file_path}\")\n","        return False\n","\n","# 손상된 이미지 파일 제거 함수\n","def remove_corrupt_images(base_dir):\n","    for root, dirs, files in os.walk(base_dir):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            if not is_image_file(file_path):\n","                os.remove(file_path)\n","\n","# 손상된 이미지 파일 제거\n","dataset_dir = '/content/drive/MyDrive/캡스톤/naver_valid_1'\n","remove_corrupt_images(dataset_dir)\n"],"metadata":{"id":"DlI5AJC8WmZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["다운로드 중 손상된 데이터 제거"],"metadata":{"id":"CBQUa_cWWo1s"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from google.colab import drive\n","\n","# Google 드라이브 마운트\n","drive.mount('/content/drive')\n","\n","# YOLOv3 설정 파일과 가중치 파일 경로\n","weights_path = '/content/drive/MyDrive/캡스톤/yolov3.weights'\n","cfg_path = '/content/drive/MyDrive/캡스톤/yolov3.cfg'\n","\n","# 함수 정의: 객체 추출 및 저장\n","def extract_objects(image_path, save_dir):\n","    # YOLOv3 모델 로드\n","    net = cv2.dnn.readNet(weights_path, cfg_path)\n","    layer_names = net.getLayerNames()\n","    output_layers_indexes = [net.getUnconnectedOutLayers()[0] - 1, net.getUnconnectedOutLayers()[1] - 1, net.getUnconnectedOutLayers()[2] - 1]\n","    output_layers = [layer_names[i] for i in output_layers_indexes]\n","\n","    # 이미지 불러오기\n","    img = cv2.imread(image_path)\n","    height, width, channels = img.shape\n","\n","    # 객체 감지를 위한 전처리\n","    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    # 감지된 객체를 리스트에 저장\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.5:\n","                center_x = int(detection[0] * width)\n","                center_y = int(detection[1] * height)\n","                w = int(detection[2] * width)\n","                h = int(detection[3] * height)\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","                # 객체의 사각형 부분만 추출하여 저장\n","                object_img = img[y:y+h, x:x+w]\n","                object_img_path = os.path.join(save_dir, f\"object_{class_id}_{confidence}.jpg\")\n","                try:\n","                    cv2.imwrite(object_img_path, object_img)\n","                except Exception as e:\n","                    print(f\"Error saving image: {e}\")\n","                    continue\n","\n","# 데이터셋 디렉토리 설정\n","dataset_dir = '/content/drive/MyDrive/캡스톤/naver_valid_1'\n","save_parent_dir = '/content/drive/MyDrive/캡스톤/naver_valid'\n","\n","# 저장할 디렉토리 생성\n","os.makedirs(save_parent_dir, exist_ok=True)\n","\n","# 클래스 디렉토리 내의 이미지 파일들을 가져와서 객체 추출 수행\n","image_files = os.listdir(dataset_dir)[:2500]  # 각 클래스당 2500개의 이미지만 사용\n","for img_file in image_files:\n","    image_path = os.path.join(dataset_dir, img_file)\n","    extract_objects(image_path, save_parent_dir)\n"],"metadata":{"id":"eQNmKPhJSUKQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["yolov3모델을 이용해 객체감지한 부분만 추출하여 데이터셋 생성"],"metadata":{"id":"q7-GleyiVKhu"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from google.colab import drive\n","\n","# Google 드라이브 마운트\n","drive.mount('/content/drive')\n","\n","# 데이터셋 디렉토리 경로\n","dataset_dir = '/content/drive/MyDrive/캡스톤/naver_valid'\n","\n","# 이미지 크기 및 채널\n","img_width, img_height, channels = 150, 150, 3\n","\n","# 클래스 개수\n","num_classes = len(os.listdir(dataset_dir))\n","\n","# 데이터 및 라벨 저장할 리스트\n","data = []\n","labels = []\n","\n","# 전체 이미지 리스트 생성\n","all_images = []\n","\n","# 디렉토리 내의 각 클래스별로 루프\n","for class_label in os.listdir(dataset_dir):\n","    class_dir = os.path.join(dataset_dir, class_label)\n","    image_files = os.listdir(class_dir)\n","    all_images.extend([(os.path.join(class_dir, img_file), class_label) for img_file in image_files])\n","\n","# 전체 데이터셋에서 랜덤하게 1000개의 샘플 선택\n","indices = np.random.choice(len(all_images), 2500, replace=False)\n","selected_images = [all_images[i] for i in indices]\n","\n","# 선택된 이미지 파일 로드 및 전처리\n","for img_path, class_label in selected_images:\n","    img = load_img(img_path, target_size=(img_width, img_height))\n","    img_array = img_to_array(img)\n","    data.append(img_array)\n","    labels.append(class_label)  # 클래스 라벨을 디렉토리 이름으로 사용\n","\n","\n","# 리스트를 넘파이 배열로 변환\n","data = np.array(data, dtype=\"float32\")\n","\n","# 각 클래스 라벨을 숫자로 변환\n","class_to_index = {class_label: i for i, class_label in enumerate(np.unique(labels))}\n","numeric_labels = np.array([class_to_index[label] for label in labels])\n","\n","# 라벨을 원-핫 인코딩\n","labels = to_categorical(numeric_labels, num_classes=len(class_to_index))\n","\n","# 데이터를 훈련 및 테스트 세트로 분할\n","train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n","\n"],"metadata":{"id":"ouLgr46LVN2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, channels)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(256, (3, 3), activation='relu'),  # 추가된 Conv2D 레이어\n","    Conv2D(256, (3, 3), activation='relu'),  # 추가된 Conv2D 레이어\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),  # 드롭아웃 추가\n","    Dense(num_classes, activation='softmax')\n","])\n"],"metadata":{"id":"s3SM0kW-Vd25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"metadata":{"id":"PTR_FfQNVfgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 모델 훈련\n","model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels))\n"],"metadata":{"id":"K9B4T3EvVhfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 모델을 저장할 경로\n","model_save_path = '/content/drive/MyDrive/캡스톤/capstone_model.h5'\n","\n","# 모델 저장\n","model.save(model_save_path)\n","\n","print(\"모델이 성공적으로 저장되었습니다.\")"],"metadata":{"id":"rjs6FyJGVnfr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델 학습 및 저장"],"metadata":{"id":"EC8NUeGnVpi3"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import img_to_array\n","\n","# YOLOv3 설정 파일과 가중치 파일 경로\n","yolo_config_path = '/content/drive/MyDrive/캡스톤/yolov3.cfg'\n","yolo_weights_path = '/content/drive/MyDrive/캡스톤/yolov3.weights'\n","\n","# 학습된 CNN 모델 경로\n","cnn_model_path = '/content/drive/MyDrive/캡스톤/capstone_model.h5'\n","\n","# YOLOv3 모델 로드\n","net = cv2.dnn.readNetFromDarknet(yolo_config_path, yolo_weights_path)\n","layer_names = net.getLayerNames()\n","output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# CNN 모델 로드\n","cnn_model = load_model(cnn_model_path)\n","\n","# 클래스 라벨 리스트\n","class_labels = [\n","    'Chest_Press_machine_images',\n","    'Lat_Pull_Down_images',\n","    'Seated_Cable_Rows_images',\n","    'arm_curl_machine_images',\n","    'chest_fly_machine_images',\n","    'chinning_dipping_images',\n","    'lateral_raises_machine_images',\n","    'leg_extension_images',\n","    'leg_press_images',\n","    'reg_curl_machine_images',\n","    'seated_dip_machine_images',\n","    'shoulder_press_machine_images',\n","    'smith_machine_images'\n","]\n","\n","def detect_and_classify_objects(image_path):\n","    # 이미지를 OpenCV 형식으로 읽음\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        return []\n","\n","    # YOLOv3 객체 탐지\n","    blob = cv2.dnn.blobFromImage(img, 0.00392, (608, 608), (0, 0, 0), True, crop=False)\n","    net.setInput(blob)\n","    outs = net.forward(output_layers)\n","\n","    # 감지된 객체를 저장할 리스트\n","    confidences = []\n","    boxes = []\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            class_id = np.argmax(scores)\n","            confidence = scores[class_id]\n","            if confidence > 0.3:  # confidence threshold를 낮춤\n","                center_x = int(detection[0] * img.shape[1])\n","                center_y = int(detection[1] * img.shape[0])\n","                w = int(detection[2] * img.shape[1])\n","                h = int(detection[3] * img.shape[0])\n","                x = int(center_x - w / 2)\n","                y = int(center_y - h / 2)\n","                boxes.append([x, y, w, h])\n","                confidences.append(float(confidence))\n","\n","    # 겹치는 박스 제거\n","    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)  # NMS threshold를 낮춤\n","\n","    # 탐지된 객체가 없을 경우 처리\n","    if len(indexes) == 0:\n","        return []\n","\n","    # 신뢰도가 가장 높은 객체 선택\n","    max_confidence_idx = indexes.flatten()[0]\n","    x, y, w, h = boxes[max_confidence_idx]\n","    crop_img = img[y:y+h, x:x+w]\n","    crop_img = cv2.resize(crop_img, (150, 150))\n","    img_array = img_to_array(crop_img)\n","    img_array = np.expand_dims(img_array, axis=0) / 255.0\n","\n","    # 분류 예측\n","    prediction = cnn_model.predict(img_array)\n","    class_idx = np.argmax(prediction)\n","    class_label = class_labels[class_idx]\n","    confidence = confidences[max_confidence_idx]\n","\n","    # 결과 저장\n","    result = {\n","        'label': class_label,\n","        'confidence': float(confidence),\n","        'box': [x, y, w, h]\n","    }\n","\n","    # 결과 반환\n","    return result\n","\n","# 테스트용 이미지 파일 경로\n","image_path = '/content/drive/MyDrive/캡스톤/naver_valid/Seated_Cable_Rows_images/Seated_Cable_Rows.png'\n","\n","# 객체 탐지 및 분류 수행\n","result = detect_and_classify_objects(image_path)\n","\n","# 결과 출력\n","if result:\n","    print(f\"Label: {result['label']}, Confidence: {result['confidence']}, Box: {result['box']}\")\n","else:\n","    print(\"No objects detected.\")\n"],"metadata":{"id":"0nHV7EY4WdM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델 평가"],"metadata":{"id":"MniuHYr2XwwR"}},{"cell_type":"code","source":["dataset_dir ='/content/drive/MyDrive/캡스톤/naver_valid'\n","\n","import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","# 전체 데이터를 불러옵니다.\n","classes = os.listdir(dataset_dir)\n","\n","# 나눌 데이터를 저장할 디렉토리 생성\n","base_dir = '/content/drive/MyDrive/캡스톤'\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'validation')\n","\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(validation_dir, exist_ok=True)\n","\n","for class_name in classes:\n","    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n","    os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n","\n","# 데이터셋 분할\n","for class_name in classes:\n","    class_dir = os.path.join(dataset_dir, class_name)\n","    images = os.listdir(class_dir)\n","    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n","\n","    for image in train_images:\n","        shutil.copy(os.path.join(class_dir, image), os.path.join(train_dir, class_name, image))\n","\n","    for image in val_images:\n","        shutil.copy(os.path.join(class_dir, image), os.path.join(validation_dir, class_name, image))\n"],"metadata":{"id":"Zqvy1QoSYWNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n"],"metadata":{"id":"U4HlY4gBYpVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 사전 학습된 모델 불러오기 (VGG16)\n","base_model = VGG19(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n","\n","# 모델 구축\n","model = Sequential()\n","model.add(base_model)\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(14, activation='softmax'))\n","\n","# 모델 컴파일\n","model.compile(optimizer=Adam(),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 조기 종료 콜백\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    validation_steps=validation_generator.samples // validation_generator.batch_size,\n","    epochs=25,\n","    validation_data=validation_generator,\n","    callbacks=[early_stopping]\n",")\n"],"metadata":{"id":"9IfkUVYbYq-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 평가\n","loss, accuracy = model.evaluate(validation_generator)\n","print(f\"Validation Loss: {loss}\")\n","print(f\"Validation Accuracy: {accuracy}\")\n","\n","# 모델 저장\n","model.save('/content/drive/MyDrive/path_to_save_model/capstone_model.h5')\n"],"metadata":{"id":"rFNAvdv9Yzpt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["VGG19를 재학습한 모델"],"metadata":{"id":"-Pf9MKR0ZMwe"}}]}